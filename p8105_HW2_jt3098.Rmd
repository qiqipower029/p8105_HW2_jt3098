---
title: "p8105_HW2_jt3098"
author: "Jieqi Tu (jt3098)"
date: "9/29/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(haven)
library(readxl)
```

```{r figure setting}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1
```{r importing data}
# Import csv data
subway_data = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>% # Upper-case --> Lower-case
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) # Retain variable needed to analyze

subway_data$entry = ifelse(subway_data$entry == "YES", TRUE, FALSE) # Make entry variable from character to logical data

```

This dataset is called subway_data. The variable it contains are below:

* line: the avenue or road in NYC that the station located in
* station_name: the names of all stations
* station_latitude: the latitude value for this station
* station_longitude: the longitude value for this station
* route1:route11: the train that stops at this station
* entry: whether or not there is entry for this station
* vending: whether or not there is vending for this station
* entrance_type: the type of the entrance
* ada:  whether or not there is ada compliance in this station

Cleaning steps:

* Import csv file from the data folder
* Use janitor::clean_names() function to convert all upper-case letters to lower-case.
* Use select function to carefully choose columns required to show up in the dataset
* Use ifelse() function to convert entry variable from character to logical.

* Dimension: rows: `r nrow(subway_data)`; columns: `r ncol(subway_data)`.
* This dataset is not tidy, because columns in this dataset are not only variables. Also, some of the columns need to be combinded or collapsed.

```{r questions}
distinction = distinct(subway_data, station_name, line) # Count the total number of stations
subway_data %>%  
  filter(ada == TRUE) %>%
  distinct(line, station_name) %>%
  nrow() # Count the total number of stations with ADA compliance
n_entrance_novending = filter(subway_data, entry == "TRUE", vending == "NO") %>%
  nrow() # Count the total number of entrance without vending
n_nonvending = filter(subway_data, vending == "NO") %>%
  nrow() # Count the total number of Exit-only without vending
```

* There are `r nrow(distinction)` distinct stations in NYC.
* There are 84 stations are ADA compliant.
* The proportion of non-vending entrance is `r n_entrance_novending / n_nonvending`

```{r reformatting}
subway_data_tidy = gather(subway_data, key = "route_number", value = "route_name", route1:route11)
```

```{r questions2}
A_stations = filter(subway_data_tidy, route_name == "A") %>%
  distinct(line, station_name) %>%
  nrow() # Total number of stations that serve A
A_compliant = filter(subway_data_tidy, route_name == "A", ada == TRUE) %>%
  distinct(line, station_name) %>%
  nrow() # Total number of stations that serve A and are ADA compliant
```

* In NYC, `r A_stations` distinct stations serve A train, `r A_compliant` of which are ADA compliant.

## Problem 2

```{r importing waterwheel data}
# Import data from excel file
waterwheel_data = read_excel(path = "./data/HealthyHarborWaterWheelTotals.xlsx", range = "A2:N256") %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = round(sports_balls, digits = 0)) %>%
  mutate(sports_balls = as.integer(sports_balls)) # Change column type to integer
```

```{r precipitation manipulation}
# Importing data from exel file
prcp_2016 = read_excel(path = "./data/HealthyHarborWaterWheelTotals.xlsx", sheet = 4, range = "A2:B14")
prcp_2017 = read_excel(path = "./data/HealthyHarborWaterWheelTotals.xlsx", sheet = 3, range = "A2:B10")

prcp_2016 = 
  prcp_2016 %>%
  janitor::clean_names() %>%
  mutate(year = 2016) # Add a new variable "year"

prcp_2017 = 
  prcp_2017 %>%
  janitor::clean_names() %>%
  mutate(year = 2017) # Add a new variable "year"

# Join dataset and stored in a new dataset
prcp_data = full_join(prcp_2016, prcp_2017)

# Change variable type by using month.name[] function
prcp_data = 
  prcp_data %>%
  mutate(month = month.name[month])
```

About these data:

* waterwheel_data is a dataset exported from HealthyHarborWaterWheelTotals.xlsx sheet 1. It contains many variables to categorize the types of trash that they collected on a specific date. For example, one of the key variable in waterwheel_data is sports balls. The mean value for sports balls in this dataset is `r mean(waterwheel_data$sports_balls)`, and the standard deviation of sports balls is `r sd(waterwheel_data$sports_balls)`. 
* There are `r nrow(waterwheel_data)` records in waterwheel_data, which implies the times that water wheels were used.
* In prcp_data, all the data are from sheet 3 and 4 of HealthyHarborWaterWheelTotals.xlsx. the precipitation was collected in `r nrow(prcp_data)` months. The number of months recorded in 2016 is `r nrow(prcp_2016)` and the number of months recorded in 2017 is `r nrow(prcp_2017)`, respectively.
* The tatol precipitation in 2017 is `r sum(prcp_2017$total)`.
* The median number for sports balls is `r waterwheel_data %>% filter(year == "2016") %>% summarize(median(sports_balls))`.

## Problem 3
```{r importing data for Problem 3}
# Import data from github website
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data(brfss_smart2010, package = "p8105.datasets")
```


```{r BRFSS data manipulation}
brfss_smart2010 = 
  brfss_smart2010 %>%
  janitor::clean_names() # The whole dataset of BRFSS file

brfss_overallhealth = 
  brfss_smart2010  %>%
  filter(topic == "Overall Health") %>% # This dataset only contains data with topic "Overal Health"
  select(-class, -topic, -sample_size, -question, -(confidence_limit_low:geo_location)) %>%
  spread(key = response, value = data_value) %>% # Make the value of response be seperate variables
  janitor::clean_names() %>%
  mutate(prop_nice = excellent + very_good) # Add a new variable to show the sum of excellent and very good proportion
```

```{r questions 3}
# Calculate the number of locations
distinct_location = distinct(brfss_overallhealth, locationdesc) %>%
  nrow()

# Calculate the number of states
distinct_states = distinct(brfss_overallhealth, locationabbr) %>%
  nrow()

# Count the most observed state
count_(brfss_overallhealth, 'locationabbr', sort = TRUE)

# Calculate the median value for excellent in 2002
brfss_2002 = 
  brfss_overallhealth %>%
  filter(year == "2002")
median(brfss_2002$excellent, na.rm = TRUE)
```

From this dataset, we could know that:

* There are `r distinct_location` different locations are included.
* There are `r distinct_states` states are included, so every state is represented. The most observed state is NJ.
* The median value for excellent response in 2002 is `r median(brfss_2002$excellent, na.rm = TRUE)`.

```{r Making plots}
# make a histogram for "Excellent" response in 2002
ggplot(brfss_2002, aes(x = excellent), alpha = .5) + 
  geom_histogram() +
  theme_bw()

# Retain data from only New York County and Queens County
excellent_N = 
  brfss_overallhealth %>%
  filter(locationdesc == "NY - New York County")
excellent_Q = 
  brfss_overallhealth %>%
  filter(locationdesc == "NY - Queens County")
excellent_NQ = rbind(excellent_N, excellent_Q)
  
# make a scatterpoint graph to show the proportion of "Excellent" in New York County and Queens County
ggplot(excellent_NQ, aes(x = year, y = excellent, color = locationdesc)) +
  geom_point() +
  labs(
    x = "Year",
    y = "Proportion of Excellent Response",
    title = "Proportion of Excellent Response in 2002 - 2010"
  ) +
  theme_bw()
```


